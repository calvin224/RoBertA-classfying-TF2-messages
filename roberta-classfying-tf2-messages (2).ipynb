{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q watermark","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-04T20:15:53.068322Z","iopub.execute_input":"2023-04-04T20:15:53.068789Z","iopub.status.idle":"2023-04-04T20:16:07.070669Z","shell.execute_reply.started":"2023-04-04T20:15:53.068746Z","shell.execute_reply":"2023-04-04T20:16:07.069309Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"%load_ext watermark\n%watermark -p torch,transformers,pandas","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:07.073870Z","iopub.execute_input":"2023-04-04T20:16:07.074776Z","iopub.status.idle":"2023-04-04T20:16:11.047821Z","shell.execute_reply.started":"2023-04-04T20:16:07.074709Z","shell.execute_reply":"2023-04-04T20:16:11.046160Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"torch       : 1.13.0+cpu\ntransformers: 4.27.4\npandas      : 1.3.5\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom tqdm.auto import tqdm\nfrom transformers import AutoTokenizer, AutoModel\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:11.049444Z","iopub.execute_input":"2023-04-04T20:16:11.050128Z","iopub.status.idle":"2023-04-04T20:16:11.588729Z","shell.execute_reply.started":"2023-04-04T20:16:11.050089Z","shell.execute_reply":"2023-04-04T20:16:11.587251Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# set seed\nnp.random.seed(42)\ntorch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:11.591933Z","iopub.execute_input":"2023-04-04T20:16:11.592475Z","iopub.status.idle":"2023-04-04T20:16:11.606214Z","shell.execute_reply.started":"2023-04-04T20:16:11.592396Z","shell.execute_reply":"2023-04-04T20:16:11.604559Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7973de20b0d0>"},"metadata":{}}]},{"cell_type":"code","source":"# set device\nDEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(\"Device:\", DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:11.609082Z","iopub.execute_input":"2023-04-04T20:16:11.609639Z","iopub.status.idle":"2023-04-04T20:16:11.616338Z","shell.execute_reply.started":"2023-04-04T20:16:11.609583Z","shell.execute_reply":"2023-04-04T20:16:11.614841Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Device: cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"# Model\nMODEL_CKPT = 'roberta-base'\nMAX_LEN = 320\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = TRAIN_BATCH_SIZE * 2\nEPOCHS = 5\nLEARNING_RATE = 2e-5\nTHRESHOLD = 0.7","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:11.618741Z","iopub.execute_input":"2023-04-04T20:16:11.619244Z","iopub.status.idle":"2023-04-04T20:16:11.629110Z","shell.execute_reply.started":"2023-04-04T20:16:11.619192Z","shell.execute_reply":"2023-04-04T20:16:11.627771Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"FOR_SUBMISSION = True","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:11.630938Z","iopub.execute_input":"2023-04-04T20:16:11.631272Z","iopub.status.idle":"2023-04-04T20:16:11.643783Z","shell.execute_reply.started":"2023-04-04T20:16:11.631240Z","shell.execute_reply":"2023-04-04T20:16:11.642276Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv')\nprint(\"Num. samples:\", len(train_data))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:11.645216Z","iopub.execute_input":"2023-04-04T20:16:11.645622Z","iopub.status.idle":"2023-04-04T20:16:13.789315Z","shell.execute_reply.started":"2023-04-04T20:16:11.645583Z","shell.execute_reply":"2023-04-04T20:16:13.787245Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Num. samples: 159571\n","output_type":"stream"}]},{"cell_type":"code","source":"label_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ntrain_data['labels'] = train_data[label_columns].apply(lambda x: list(x), axis=1)\n\ntrain_data.drop(['id'], inplace=True, axis=1)\ntrain_data.drop(label_columns, inplace=True, axis=1)\n\ntrain_data.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:13.791548Z","iopub.execute_input":"2023-04-04T20:16:13.792286Z","iopub.status.idle":"2023-04-04T20:16:15.978257Z","shell.execute_reply.started":"2023-04-04T20:16:13.792214Z","shell.execute_reply":"2023-04-04T20:16:15.976820Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                        comment_text              labels\n0  Explanation\\nWhy the edits made under my usern...  [0, 0, 0, 0, 0, 0]\n1  D'aww! He matches this background colour I'm s...  [0, 0, 0, 0, 0, 0]\n2  Hey man, I'm really not trying to edit war. It...  [0, 0, 0, 0, 0, 0]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def clean_text(txt):\n    txt = txt.lower()  # convert to lowercase\n    txt = re.sub(r'\\d+', '', txt)  # remove numbers\n    txt = re.sub(r'[^\\w\\s]', '', txt)  # remove punctuation\n    txt = re.sub(r'\\s+', ' ', txt)  # remove extra spaces\n    return txt.strip()\n\ntrain_data['comment_text'] = train_data['comment_text'].apply(lambda x: clean_text(x))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:15.983065Z","iopub.execute_input":"2023-04-04T20:16:15.983516Z","iopub.status.idle":"2023-04-04T20:16:23.257035Z","shell.execute_reply.started":"2023-04-04T20:16:15.983473Z","shell.execute_reply":"2023-04-04T20:16:23.256033Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# split data\ntrain_size = 0.85\ntrain_df = train_data.sample(frac=train_size, random_state=123)\nval_df = train_data.drop(train_df.index).reset_index(drop=True)\ntrain_df = train_df.reset_index(drop=True)\n\nprint(\"Orig Dataset: {}\".format(train_data.shape))\nprint(\"Training Dataset: {}\".format(train_df.shape))\nprint(\"Validation Dataset: {}\".format(val_df.shape))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:23.258725Z","iopub.execute_input":"2023-04-04T20:16:23.259869Z","iopub.status.idle":"2023-04-04T20:16:23.363345Z","shell.execute_reply.started":"2023-04-04T20:16:23.259739Z","shell.execute_reply":"2023-04-04T20:16:23.361401Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Orig Dataset: (159571, 2)\nTraining Dataset: (135635, 2)\nValidation Dataset: (23936, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# create dataset and dataloaders\ntokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:23.365131Z","iopub.execute_input":"2023-04-04T20:16:23.365640Z","iopub.status.idle":"2023-04-04T20:16:28.033751Z","shell.execute_reply.started":"2023-04-04T20:16:23.365595Z","shell.execute_reply":"2023-04-04T20:16:28.032240Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"359c27cc51264c2eb09cb699c70aaa48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70b9745d0871493a91e46d294842d98a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc7174a06b614fbc99af44b102460e54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1420dd5180be4e5e864cccfb78c42994"}},"metadata":{}}]},{"cell_type":"code","source":"class MultiLabelDataset(Dataset):\n\n    def __init__(self, dataframe, tokenizer, max_len, new_data=False):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.text = dataframe.comment_text\n        self.new_data = new_data\n        self.max_len = max_len\n        \n        if not new_data:\n            self.targets = self.data.labels\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        text = str(self.text[index])\n        text = \" \".join(text.split())\n        text = clean_text(text)\n\n        inputs = self.tokenizer(\n            text, \n            truncation=True, \n            padding='max_length' if self.new_data else False,\n            max_length=self.max_len, \n            return_tensors=\"pt\"\n        )\n        inputs = {k: v.squeeze() for k, v in inputs.items()}\n        \n        if not self.new_data:\n            labels = torch.tensor(self.targets[index], dtype=torch.float)\n            return inputs, labels\n\n        return inputs\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:28.035634Z","iopub.execute_input":"2023-04-04T20:16:28.036404Z","iopub.status.idle":"2023-04-04T20:16:28.049846Z","shell.execute_reply.started":"2023-04-04T20:16:28.036340Z","shell.execute_reply":"2023-04-04T20:16:28.048204Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = MultiLabelDataset(train_df, tokenizer, MAX_LEN)\nval_dataset = MultiLabelDataset(val_df, tokenizer, MAX_LEN)\n\ntrain_sampler = RandomSampler(train_dataset)\ntrain_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE, num_workers=4, pin_memory=True)\n\nval_sampler = SequentialSampler(val_dataset)\nval_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=VALID_BATCH_SIZE, num_workers=4, pin_memory=True)\n\nprint(\"Train Dataset:\", len(train_dataset))\nprint(\"Validation Dataset:\", len(val_dataset))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:28.052239Z","iopub.execute_input":"2023-04-04T20:16:28.052801Z","iopub.status.idle":"2023-04-04T20:16:28.067248Z","shell.execute_reply.started":"2023-04-04T20:16:28.052737Z","shell.execute_reply":"2023-04-04T20:16:28.065349Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Train Dataset: 135635\nValidation Dataset: 23936\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_CKPT, do_lower_case=True)\n\ntrain_set = MultiLabelDataset(train_df, tokenizer, MAX_LEN)\nval_set = MultiLabelDataset(val_df, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:28.069346Z","iopub.execute_input":"2023-04-04T20:16:28.070272Z","iopub.status.idle":"2023-04-04T20:16:29.275323Z","shell.execute_reply.started":"2023-04-04T20:16:28.070215Z","shell.execute_reply":"2023-04-04T20:16:29.273985Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def dynamic_collate(data):\n    \"\"\"Custom data collator for dynamic padding.\"\"\"\n    inputs = [d for d,l in data]\n    labels = torch.stack([l for d,l in data], dim=0)\n    inputs = tokenizer.pad(inputs, return_tensors='pt')\n    return inputs, labels","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:29.277098Z","iopub.execute_input":"2023-04-04T20:16:29.277629Z","iopub.status.idle":"2023-04-04T20:16:29.285829Z","shell.execute_reply.started":"2023-04-04T20:16:29.277572Z","shell.execute_reply":"2023-04-04T20:16:29.284516Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 2, \n                'collate_fn': dynamic_collate}\n\nval_params = {'batch_size': VALID_BATCH_SIZE,\n              'shuffle': False,\n              'num_workers': 2, \n              'collate_fn': dynamic_collate}\n\ntrain_loader = DataLoader(train_set, **train_params)\nval_loader = None if FOR_SUBMISSION else DataLoader(val_set, **val_params)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:29.287746Z","iopub.execute_input":"2023-04-04T20:16:29.288148Z","iopub.status.idle":"2023-04-04T20:16:29.305058Z","shell.execute_reply.started":"2023-04-04T20:16:29.288111Z","shell.execute_reply":"2023-04-04T20:16:29.303836Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class TransformerModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.roberta = AutoModel.from_pretrained(MODEL_CKPT)\n        self.classifier = nn.Sequential(\n            nn.Linear(768, 768),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(768, 6)\n        )\n\n    def forward(self, inputs):\n        roberta_output = self.roberta(**inputs)\n        hidden_state = roberta_output.last_hidden_state\n        pooled_out = hidden_state[:, 0]\n        logits = self.classifier(pooled_out)\n        return logits\n\n\n\nmodel = TransformerModel()\nmodel.to(DEVICE);","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:29.306573Z","iopub.execute_input":"2023-04-04T20:16:29.306974Z","iopub.status.idle":"2023-04-04T20:16:35.928633Z","shell.execute_reply.started":"2023-04-04T20:16:29.306937Z","shell.execute_reply":"2023-04-04T20:16:35.927197Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d7826f9ddf649cba5fdd11c40181dda"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\nloss_func = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:35.930428Z","iopub.execute_input":"2023-04-04T20:16:35.930800Z","iopub.status.idle":"2023-04-04T20:16:35.938315Z","shell.execute_reply.started":"2023-04-04T20:16:35.930765Z","shell.execute_reply":"2023-04-04T20:16:35.936956Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"lr_sched = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.2)\ntest_df = pd.read_csv('/kaggle/input/tf2chatsunlabelled/chatlog.csv')\ntest_df.head(80)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:35.940103Z","iopub.execute_input":"2023-04-04T20:16:35.940785Z","iopub.status.idle":"2023-04-04T20:16:36.580466Z","shell.execute_reply.started":"2023-04-04T20:16:35.940746Z","shell.execute_reply":"2023-04-04T20:16:36.579155Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"             steamid          name comment_text  toxic  severe_toxic  obscene  \\\n0    [U:1:158517868]  Orange-Juice      bad spy    NaN           NaN      NaN   \n1    [U:1:158517868]  Orange-Juice           :(    NaN           NaN      NaN   \n2    [U:1:236710169]  CUNNY PLEASE         loll    NaN           NaN      NaN   \n3    [U:1:174480808]          kris           gg    NaN           NaN      NaN   \n4    [U:1:236710169]  CUNNY PLEASE       insane    NaN           NaN      NaN   \n..               ...           ...          ...    ...           ...      ...   \n75   [U:1:378260322]            AG           sb    NaN           NaN      NaN   \n76   [U:1:378260322]            AG           sb    NaN           NaN      NaN   \n77  [U:1:1210179367]         小灰灰本人            6    NaN           NaN      NaN   \n78  [U:1:1210179367]         小灰灰本人          .SS    NaN           NaN      NaN   \n79  [U:1:1210179367]         小灰灰本人          .SS    NaN           NaN      NaN   \n\n    threat  insult  identity_hate  \n0      NaN     NaN            NaN  \n1      NaN     NaN            NaN  \n2      NaN     NaN            NaN  \n3      NaN     NaN            NaN  \n4      NaN     NaN            NaN  \n..     ...     ...            ...  \n75     NaN     NaN            NaN  \n76     NaN     NaN            NaN  \n77     NaN     NaN            NaN  \n78     NaN     NaN            NaN  \n79     NaN     NaN            NaN  \n\n[80 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>steamid</th>\n      <th>name</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[U:1:158517868]</td>\n      <td>Orange-Juice</td>\n      <td>bad spy</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[U:1:158517868]</td>\n      <td>Orange-Juice</td>\n      <td>:(</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[U:1:236710169]</td>\n      <td>CUNNY PLEASE</td>\n      <td>loll</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[U:1:174480808]</td>\n      <td>kris</td>\n      <td>gg</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[U:1:236710169]</td>\n      <td>CUNNY PLEASE</td>\n      <td>insane</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>[U:1:378260322]</td>\n      <td>AG</td>\n      <td>sb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>[U:1:378260322]</td>\n      <td>AG</td>\n      <td>sb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>[U:1:1210179367]</td>\n      <td>小灰灰本人</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>[U:1:1210179367]</td>\n      <td>小灰灰本人</td>\n      <td>.SS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>79</th>\n      <td>[U:1:1210179367]</td>\n      <td>小灰灰本人</td>\n      <td>.SS</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):\n    \"\"\"An accuracy metric for multi-label problems.\"\"\"\n    if sigmoid: \n        inp = inp.sigmoid()\n    return ((inp > thresh) == targ.bool()).float().mean()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:36.582454Z","iopub.execute_input":"2023-04-04T20:16:36.582942Z","iopub.status.idle":"2023-04-04T20:16:36.590026Z","shell.execute_reply.started":"2023-04-04T20:16:36.582890Z","shell.execute_reply":"2023-04-04T20:16:36.588640Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(train_loader, model, loss_func, optimizer, progress_bar=None):\n    \"\"\"Train model over one epoch.\"\"\"\n    model.train()\n    size = len(train_loader.dataset)  # Train set size\n    \n    for i, (data, targets) in enumerate(train_loader):\n        # Put inputs and target on DEVICE\n        data = {k: v.to(DEVICE) for k, v in data.items()}\n        targets = targets.to(DEVICE)\n        \n        outputs = model(data)\n        loss = loss_func(outputs, targets)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if progress_bar is not None:\n            progress_bar.update(1)\n        \n        if i % 1000 == 0:\n            loss, step = loss.item(), i * len(targets)\n            print(f\"Loss: {loss:>4f}  [{step:>6d}/{size:>6d}]\")\n        elif i == len(train_loader) - 1:\n            loss = loss.item()\n            print(f\"Loss: {loss:>4f}  [{size:>6d}/{size:>6d}]\")","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:36.592144Z","iopub.execute_input":"2023-04-04T20:16:36.592949Z","iopub.status.idle":"2023-04-04T20:16:36.604543Z","shell.execute_reply.started":"2023-04-04T20:16:36.592897Z","shell.execute_reply":"2023-04-04T20:16:36.603319Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def validate_one_epoch(val_loader, model, loss_func):\n    \"\"\"Validate model over one epoch.\"\"\"\n    model.eval()\n    num_batches = len(val_loader)\n    \n    valid_loss, acc_multi = 0, 0\n\n    with torch.no_grad():\n        for _, (data, targets) in enumerate(val_loader):\n            data = {k: v.to(DEVICE) for k, v in data.items()}\n            targets = targets.to(DEVICE)\n\n            outputs = model(data)\n            valid_loss += loss_func(outputs, targets).item()\n            acc_multi += accuracy_multi(outputs, targets)\n\n    valid_loss /= num_batches  # Avg. loss\n    acc_multi /= num_batches   # Avg. acc. multi\n    print(f\"Avg. valid. loss: {valid_loss:>4f}, Acc. multi: {acc_multi:>4f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:36.606896Z","iopub.execute_input":"2023-04-04T20:16:36.607442Z","iopub.status.idle":"2023-04-04T20:16:36.621839Z","shell.execute_reply.started":"2023-04-04T20:16:36.607373Z","shell.execute_reply":"2023-04-04T20:16:36.620545Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"num_train_steps = EPOCHS * len(train_loader)\nprogress_bar = tqdm(range(num_train_steps))\n\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch+1} (lr = {lr_sched.get_last_lr()[0]:.2e})\\n-------------------------------\")\n    train_one_epoch(train_loader, model, loss_func, optimizer, progress_bar)\n    if not FOR_SUBMISSION:\n        validate_one_epoch(val_loader, model, loss_func)\n    lr_sched.step()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T20:16:36.623327Z","iopub.execute_input":"2023-04-04T20:16:36.623735Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/21195 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5255e97d0f8b409c902abdeb8890363d"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 (lr = 2.00e-05)\n-------------------------------\n","output_type":"stream"},{"name":"stderr","text":"You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\nYou're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"name":"stdout","text":"Loss: 0.706802  [     0/135635]\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/tf2chatsunlabelled/chatlog.csv')\n\ntest_df.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_params = {'batch_size': VALID_BATCH_SIZE,\n               'shuffle': False,\n               'num_workers': 2}\n\ntest_set = MultiLabelDataset(test_df, tokenizer, MAX_LEN, new_data=True)\ntest_loader = DataLoader(test_set, **test_params)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(test_loader, model):\n    \"\"\"Make predictions on test set.\"\"\"\n    model.eval()\n    all_preds = []\n    \n    with torch.inference_mode():\n        for data in tqdm(test_loader):\n            data = {k: v.to(DEVICE) for k, v in data.items()}\n\n            outputs = model(data)\n            probas = torch.sigmoid(outputs)\n\n            all_preds.append(probas)\n            \n        all_preds = torch.cat(all_preds)\n    return all_preds.cpu()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_test_pred = predict(test_loader, model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df = test_df.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, name in enumerate(label_columns):\n    submit_df[name] = all_test_pred[:, i]\n\nsubmit_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n\nsubmit_df.to_csv('Chatslabelled.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}